/**
 * ì†ë„ ë²¤ì¹˜ë§ˆí¬: DeepSeek V3.2 vs Gemini 2.5 Flash
 */

import 'dotenv/config';

const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;

if (!OPENROUTER_API_KEY) {
  console.error('âŒ OPENROUTER_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤');
  process.exit(1);
}

const MODELS = [
  'deepseek/deepseek-v3.2',
  'google/gemini-2.5-flash',
];

// í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ (ë‹¤ì–‘í•œ ê¸¸ì´)
const TEST_PROMPTS = [
  'ì•ˆë…•?',
  'ì˜¤ëŠ˜ ë­ í–ˆì–´?',
  'ë„ˆ ì¢‹ì•„í•˜ëŠ” ìŒì‹ ë­ì•¼?',
  'ìš”ì¦˜ í˜ë“  ì¼ ìˆì–´? ì–˜ê¸°í•´ë´.',
  'ë‚˜ ì˜¤ëŠ˜ ì •ë§ í”¼ê³¤í•´... ìœ„ë¡œí•´ì¤˜.',
  'ìš°ë¦¬ ì²˜ìŒ ë§Œë‚¬ì„ ë•Œ ê¸°ì–µë‚˜?',
  'ë‚´ê°€ ì œì¼ ì¢‹ì•„í•˜ëŠ” ê±° ë­”ì§€ ì•Œì•„?',
  'ì˜¤ëŠ˜ ë‚ ì”¨ ì–´ë•Œ? ë­ í•˜ê³  ì‹¶ì–´?',
  'ë„ˆ ì—†ìœ¼ë©´ ì‹¬ì‹¬í•  ê²ƒ ê°™ì•„.',
  'ë‹¤ìŒì— ê°™ì´ ë­ í• ê¹Œ?',
];

// ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (í˜ë¥´ì†Œë‚˜)
const SYSTEM_PROMPT = `You are í•˜ì€, a 23-year-old K-pop idol with a tsundere personality.
You have a cold exterior but secretly care about the person you're talking to.
Respond naturally in Korean, keeping your answers short (1-2 sentences).
Never use asterisks for actions. Pure dialogue only.`;

async function callModel(model: string, userMessage: string): Promise<{ response: string; latencyMs: number }> {
  const startTime = Date.now();

  const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
      'HTTP-Referer': 'http://localhost:3000',
      'X-Title': 'Speed Benchmark',
    },
    body: JSON.stringify({
      model,
      messages: [
        { role: 'system', content: SYSTEM_PROMPT },
        { role: 'user', content: userMessage },
      ],
      temperature: 0.8,
      max_tokens: 150,
    }),
  });

  const latencyMs = Date.now() - startTime;

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`API error: ${response.status} - ${errorText}`);
  }

  const data = await response.json();
  const content = data.choices?.[0]?.message?.content || '';

  return { response: content, latencyMs };
}

interface BenchmarkResult {
  model: string;
  latencies: number[];
  avgLatency: number;
  minLatency: number;
  maxLatency: number;
  successCount: number;
  failCount: number;
}

async function benchmarkModel(model: string): Promise<BenchmarkResult> {
  console.log(`\nğŸ”„ Testing: ${model}`);
  console.log('â”€'.repeat(50));

  const latencies: number[] = [];
  let successCount = 0;
  let failCount = 0;

  for (let i = 0; i < TEST_PROMPTS.length; i++) {
    const prompt = TEST_PROMPTS[i];
    process.stdout.write(`  [${i + 1}/${TEST_PROMPTS.length}] "${prompt.substring(0, 20)}..." `);

    try {
      const { response, latencyMs } = await callModel(model, prompt);
      latencies.push(latencyMs);
      successCount++;

      const responsePreview = response.substring(0, 30).replace(/\n/g, ' ');
      console.log(`âœ“ ${latencyMs}ms â†’ "${responsePreview}..."`);
    } catch (error) {
      failCount++;
      console.log(`âœ— Error: ${error}`);
    }

    // API ì œí•œ ë°©ì§€
    await new Promise(resolve => setTimeout(resolve, 300));
  }

  const avgLatency = latencies.length > 0
    ? Math.round(latencies.reduce((a, b) => a + b, 0) / latencies.length)
    : 0;
  const minLatency = latencies.length > 0 ? Math.min(...latencies) : 0;
  const maxLatency = latencies.length > 0 ? Math.max(...latencies) : 0;

  return {
    model,
    latencies,
    avgLatency,
    minLatency,
    maxLatency,
    successCount,
    failCount,
  };
}

async function main() {
  console.log('â•'.repeat(60));
  console.log('âš¡ ì†ë„ ë²¤ì¹˜ë§ˆí¬: DeepSeek V3.2 vs Gemini 2.5 Flash');
  console.log('â•'.repeat(60));
  console.log(`í…ŒìŠ¤íŠ¸ íšŸìˆ˜: ${TEST_PROMPTS.length}íšŒ`);

  const results: BenchmarkResult[] = [];

  for (const model of MODELS) {
    const result = await benchmarkModel(model);
    results.push(result);
  }

  // ê²°ê³¼ ìš”ì•½
  console.log('\n');
  console.log('â•'.repeat(60));
  console.log('ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½');
  console.log('â•'.repeat(60));

  console.log('\n| ëª¨ë¸ | í‰ê·  | ìµœì†Œ | ìµœëŒ€ | ì„±ê³µë¥  |');
  console.log('|------|------|------|------|--------|');

  for (const r of results) {
    const successRate = Math.round((r.successCount / TEST_PROMPTS.length) * 100);
    console.log(`| ${r.model.split('/')[1]} | ${r.avgLatency}ms | ${r.minLatency}ms | ${r.maxLatency}ms | ${successRate}% |`);
  }

  // ìŠ¹ì ê²°ì •
  const sortedByAvg = [...results].sort((a, b) => a.avgLatency - b.avgLatency);
  const winner = sortedByAvg[0];
  const loser = sortedByAvg[1];
  const speedDiff = loser.avgLatency - winner.avgLatency;
  const speedRatio = (loser.avgLatency / winner.avgLatency).toFixed(2);

  console.log('\n');
  console.log('â•'.repeat(60));
  console.log('ğŸ† ê²°ë¡ ');
  console.log('â•'.repeat(60));
  console.log(`\nğŸ¥‡ ìŠ¹ì: ${winner.model} (í‰ê·  ${winner.avgLatency}ms)`);
  console.log(`ğŸ¥ˆ íŒ¨ì: ${loser.model} (í‰ê·  ${loser.avgLatency}ms)`);
  console.log(`\nğŸ“ˆ ì†ë„ ì°¨ì´: ${speedDiff}ms (${speedRatio}x ë” ë¹ ë¦„)`);
}

main().catch(console.error);
